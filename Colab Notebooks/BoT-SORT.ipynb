{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bZkLds7sxWPl","outputId":"4688d28b-8756-4634-a004-ccf448ada25f","executionInfo":{"status":"ok","timestamp":1659306906230,"user_tz":-300,"elapsed":39964,"user":{"displayName":"Mujtaba Akbar","userId":"15620186712641886307"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'BoT-SORT'...\n","remote: Enumerating objects: 983, done.\u001b[K\n","remote: Counting objects: 100% (190/190), done.\u001b[K\n","remote: Compressing objects: 100% (143/143), done.\u001b[K\n","remote: Total 983 (delta 75), reused 133 (delta 41), pack-reused 793\u001b[K\n","Receiving objects: 100% (983/983), 55.73 MiB | 19.00 MiB/s, done.\n","Resolving deltas: 100% (223/223), done.\n","/content/BoT-SORT\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.21.6)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (4.6.0.66)\n","Collecting loguru\n","  Downloading loguru-0.6.0-py3-none-any.whl (58 kB)\n","\u001b[K     |████████████████████████████████| 58 kB 1.7 MB/s \n","\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (0.18.3)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.0.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (4.64.0)\n","Requirement already satisfied: torchvision>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (0.13.0+cu113)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (7.1.2)\n","Collecting thop\n","  Downloading thop-0.1.1.post2207130030-py3-none-any.whl (15 kB)\n","Collecting ninja\n","  Downloading ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n","\u001b[K     |████████████████████████████████| 108 kB 14.0 MB/s \n","\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (0.8.10)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (2.8.0)\n","Collecting lap\n","  Downloading lap-0.4.0.tar.gz (1.5 MB)\n","\u001b[K     |████████████████████████████████| 1.5 MB 65.2 MB/s \n","\u001b[?25hCollecting motmetrics\n","  Downloading motmetrics-1.2.5-py3-none-any.whl (161 kB)\n","\u001b[K     |████████████████████████████████| 161 kB 67.8 MB/s \n","\u001b[?25hCollecting filterpy\n","  Downloading filterpy-1.4.5.zip (177 kB)\n","\u001b[K     |████████████████████████████████| 177 kB 70.2 MB/s \n","\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 16)) (3.1.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 17)) (3.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 18)) (1.7.3)\n","Requirement already satisfied: prettytable in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 19)) (3.3.0)\n","Requirement already satisfied: easydict in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 20)) (1.9)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 22)) (3.13)\n","Collecting yacs\n","  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 24)) (1.1.0)\n","Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 25)) (4.4.0)\n","Collecting onnx==1.8.1\n","  Downloading onnx-1.8.1-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\n","\u001b[K     |████████████████████████████████| 14.5 MB 32.4 MB/s \n","\u001b[?25hCollecting onnxruntime==1.8.0\n","  Downloading onnxruntime-1.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n","\u001b[K     |████████████████████████████████| 4.5 MB 59.2 MB/s \n","\u001b[?25hCollecting onnx-simplifier==0.3.5\n","  Downloading onnx-simplifier-0.3.5.tar.gz (13 kB)\n","Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx==1.8.1->-r requirements.txt (line 26)) (4.1.1)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnx==1.8.1->-r requirements.txt (line 26)) (3.17.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from onnx==1.8.1->-r requirements.txt (line 26)) (1.15.0)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime==1.8.0->-r requirements.txt (line 27)) (2.0)\n","Collecting onnxoptimizer>=0.2.5\n","  Downloading onnxoptimizer-0.2.7-cp37-cp37m-manylinux2014_x86_64.whl (498 kB)\n","\u001b[K     |████████████████████████████████| 498 kB 72.0 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.10.0->-r requirements.txt (line 7)) (2.23.0)\n","Requirement already satisfied: torch==1.12.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.10.0->-r requirements.txt (line 7)) (1.12.0+cu113)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 4)) (1.3.0)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 4)) (2021.11.2)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 4)) (2.4.1)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 4)) (2.6.3)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 17)) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 17)) (3.0.9)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 17)) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 17)) (1.4.4)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r requirements.txt (line 5)) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r requirements.txt (line 5)) (3.1.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 12)) (1.8.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 12)) (0.37.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 12)) (0.6.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 12)) (1.0.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 12)) (1.47.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 12)) (3.4.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 12)) (1.35.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 12)) (1.2.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 12)) (57.4.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 12)) (0.4.6)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 12)) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 12)) (4.9)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 12)) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 12)) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->-r requirements.txt (line 12)) (4.12.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->-r requirements.txt (line 12)) (3.8.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 12)) (0.4.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.10.0->-r requirements.txt (line 7)) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.10.0->-r requirements.txt (line 7)) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.10.0->-r requirements.txt (line 7)) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.10.0->-r requirements.txt (line 7)) (2.10)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 12)) (3.2.0)\n","Requirement already satisfied: pandas>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from motmetrics->-r requirements.txt (line 14)) (1.3.5)\n","Collecting xmltodict>=0.12.0\n","  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.1->motmetrics->-r requirements.txt (line 14)) (2022.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->-r requirements.txt (line 16)) (1.5.2)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prettytable->-r requirements.txt (line 19)) (0.2.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown->-r requirements.txt (line 25)) (3.7.1)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown->-r requirements.txt (line 25)) (4.6.3)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.10.0->-r requirements.txt (line 7)) (1.7.1)\n","Building wheels for collected packages: onnx-simplifier, lap, filterpy\n","  Building wheel for onnx-simplifier (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for onnx-simplifier: filename=onnx_simplifier-0.3.5-py3-none-any.whl size=12878 sha256=5c8810e3b82ca8b75259f1ca0c3437d0da6795a252d9aa6355a601fccf9c198a\n","  Stored in directory: /root/.cache/pip/wheels/8a/b4/1b/6acdd4eb854b215cd4aa1c18ca79399f9d34728edaff47ecce\n","  Building wheel for lap (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for lap: filename=lap-0.4.0-cp37-cp37m-linux_x86_64.whl size=1590224 sha256=b02d5fdc5c15970fd862b9376cbedf002a7871bd8c2acf85efd08f6565f8bf89\n","  Stored in directory: /root/.cache/pip/wheels/b1/0b/e3/ef9daf1b5547b56389e42c80c3100f1e6479bf5fd00fd9d6ba\n","  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110474 sha256=638a9d323c4feb1ea5b6d931360d9fd335728a2f2e21961e9e87ad3232ca051b\n","  Stored in directory: /root/.cache/pip/wheels/ce/e0/ee/a2b3c5caab3418c1ccd8c4de573d4cbe13315d7e8b0a55fbc2\n","Successfully built onnx-simplifier lap filterpy\n","Installing collected packages: onnx, xmltodict, onnxruntime, onnxoptimizer, yacs, thop, onnx-simplifier, ninja, motmetrics, loguru, lap, filterpy\n","Successfully installed filterpy-1.4.5 lap-0.4.0 loguru-0.6.0 motmetrics-1.2.5 ninja-1.10.2.3 onnx-1.8.1 onnx-simplifier-0.3.5 onnxoptimizer-0.2.7 onnxruntime-1.8.0 thop-0.1.1.post2207130030 xmltodict-0.13.0 yacs-0.1.8\n","running develop\n","running egg_info\n","creating yolox.egg-info\n","writing yolox.egg-info/PKG-INFO\n","writing dependency_links to yolox.egg-info/dependency_links.txt\n","writing top-level names to yolox.egg-info/top_level.txt\n","writing manifest file 'yolox.egg-info/SOURCES.txt'\n","package init file 'VideoCameraCorrection/__init__.py' not found (or not a regular file)\n","package init file 'tracker/__init__.py' not found (or not a regular file)\n","package init file 'tools/__init__.py' not found (or not a regular file)\n","package init file 'assets/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/__init__.py' not found (or not a regular file)\n","package init file 'yolov7/__init__.py' not found (or not a regular file)\n","package init file 'yolox/exps/__init__.py' not found (or not a regular file)\n","package init file 'yolox/layers/csrc/__init__.py' not found (or not a regular file)\n","package init file 'yolox/layers/csrc/cocoeval/__init__.py' not found (or not a regular file)\n","package init file 'yolox/exps/example/__init__.py' not found (or not a regular file)\n","package init file 'yolox/exps/default/__init__.py' not found (or not a regular file)\n","package init file 'yolox/exps/example/mot/__init__.py' not found (or not a regular file)\n","package init file 'VideoCameraCorrection/VideoCameraCorrection/__init__.py' not found (or not a regular file)\n","package init file 'tracker/tracking_utils/__init__.py' not found (or not a regular file)\n","package init file 'tracker/GMC_files/__init__.py' not found (or not a regular file)\n","package init file 'tracker/GMC_files/MOT17_ablation/__init__.py' not found (or not a regular file)\n","package init file 'tracker/GMC_files/MOTChallenge/__init__.py' not found (or not a regular file)\n","package init file 'tools/datasets/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/docs/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/docker/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/projects/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/configs/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/datasets/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/tools/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/demo/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/docs/_static/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/docs/modules/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/docs/_static/css/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/fastreid/modeling/backbones/regnet/regnety/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/fastreid/modeling/backbones/regnet/effnet/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/fastreid/modeling/backbones/regnet/regnetx/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/projects/FastClas/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/projects/FastRT/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/projects/NAIC20/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/projects/FastTune/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/projects/FastRetri/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/projects/FastAttr/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/projects/DG-ReID/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/projects/CrossDomainReID/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/projects/FastFace/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/projects/HAA/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/projects/PartialReID/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/projects/FastDistill/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/projects/FastClas/configs/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/projects/FastRT/third_party/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/projects/FastRT/pybind_interface/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/projects/FastRT/include/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/projects/FastRT/fastrt/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/projects/FastRT/docker/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/projects/FastRT/tools/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/projects/FastRT/demo/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/projects/FastRT/third_party/cnpy/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/projects/FastRT/pybind_interface/docker/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/projects/FastRT/pybind_interface/docker/trt7cu102_torch160/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/projects/FastRT/pybind_interface/docker/trt7cu100/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/projects/FastRT/include/fastrt/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/projects/FastRT/fastrt/layers/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/projects/FastRT/fastrt/meta_arch/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/projects/FastRT/fastrt/backbones/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/projects/FastRT/fastrt/engine/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/projects/FastRT/fastrt/factory/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/projects/FastRT/fastrt/common/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/projects/FastRT/fastrt/heads/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/projects/FastRT/docker/trt7cu102/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/projects/FastRT/docker/trt7cu100/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/projects/NAIC20/configs/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/projects/FastTune/configs/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/projects/FastRetri/configs/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/projects/FastAttr/configs/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/projects/FastFace/configs/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/projects/PartialReID/configs/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/projects/FastDistill/configs/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/configs/MOT17/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/configs/DukeMTMC/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/configs/VehicleID/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/configs/Market1501/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/configs/VERIWild/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/configs/MOT20/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/configs/VeRi/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/configs/MSMT17/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/tools/deploy/__init__.py' not found (or not a regular file)\n","package init file 'fast_reid/tools/deploy/test_data/__init__.py' not found (or not a regular file)\n","package init file 'yolov7/figure/__init__.py' not found (or not a regular file)\n","package init file 'yolov7/scripts/__init__.py' not found (or not a regular file)\n","package init file 'yolov7/data/__init__.py' not found (or not a regular file)\n","package init file 'yolov7/inference/__init__.py' not found (or not a regular file)\n","package init file 'yolov7/cfg/__init__.py' not found (or not a regular file)\n","package init file 'yolov7/tools/__init__.py' not found (or not a regular file)\n","package init file 'yolov7/inference/images/__init__.py' not found (or not a regular file)\n","package init file 'yolov7/cfg/deploy/__init__.py' not found (or not a regular file)\n","package init file 'yolov7/cfg/baseline/__init__.py' not found (or not a regular file)\n","package init file 'yolov7/cfg/training/__init__.py' not found (or not a regular file)\n","package init file 'yolov7/utils/google_app_engine/__init__.py' not found (or not a regular file)\n","adding license file 'LICENSE'\n","writing manifest file 'yolox.egg-info/SOURCES.txt'\n","running build_ext\n","building 'yolox._C' extension\n","creating /content/BoT-SORT/build\n","creating /content/BoT-SORT/build/temp.linux-x86_64-3.7\n","creating /content/BoT-SORT/build/temp.linux-x86_64-3.7/content\n","creating /content/BoT-SORT/build/temp.linux-x86_64-3.7/content/BoT-SORT\n","creating /content/BoT-SORT/build/temp.linux-x86_64-3.7/content/BoT-SORT/yolox\n","creating /content/BoT-SORT/build/temp.linux-x86_64-3.7/content/BoT-SORT/yolox/layers\n","creating /content/BoT-SORT/build/temp.linux-x86_64-3.7/content/BoT-SORT/yolox/layers/csrc\n","creating /content/BoT-SORT/build/temp.linux-x86_64-3.7/content/BoT-SORT/yolox/layers/csrc/cocoeval\n","Emitting ninja build file /content/BoT-SORT/build/temp.linux-x86_64-3.7/build.ninja...\n","Compiling objects...\n","Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n","[1/2] c++ -MMD -MF /content/BoT-SORT/build/temp.linux-x86_64-3.7/content/BoT-SORT/yolox/layers/csrc/cocoeval/cocoeval.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/content/BoT-SORT/yolox/layers/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/include/python3.7m -c -c /content/BoT-SORT/yolox/layers/csrc/cocoeval/cocoeval.cpp -o /content/BoT-SORT/build/temp.linux-x86_64-3.7/content/BoT-SORT/yolox/layers/csrc/cocoeval/cocoeval.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1013\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n","[2/2] c++ -MMD -MF /content/BoT-SORT/build/temp.linux-x86_64-3.7/content/BoT-SORT/yolox/layers/csrc/vision.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/content/BoT-SORT/yolox/layers/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/include/python3.7m -c -c /content/BoT-SORT/yolox/layers/csrc/vision.cpp -o /content/BoT-SORT/build/temp.linux-x86_64-3.7/content/BoT-SORT/yolox/layers/csrc/vision.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1013\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n","creating build/lib.linux-x86_64-3.7\n","creating build/lib.linux-x86_64-3.7/yolox\n","x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 /content/BoT-SORT/build/temp.linux-x86_64-3.7/content/BoT-SORT/yolox/layers/csrc/vision.o /content/BoT-SORT/build/temp.linux-x86_64-3.7/content/BoT-SORT/yolox/layers/csrc/cocoeval/cocoeval.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.7/yolox/_C.cpython-37m-x86_64-linux-gnu.so\n","copying build/lib.linux-x86_64-3.7/yolox/_C.cpython-37m-x86_64-linux-gnu.so -> yolox\n","Creating /usr/local/lib/python3.7/dist-packages/yolox.egg-link (link to .)\n","Adding yolox 0.1.0 to easy-install.pth file\n","\n","Installed /content/BoT-SORT\n","Processing dependencies for yolox==0.1.0\n","Finished processing dependencies for yolox==0.1.0\n"]}],"source":["!git clone https://github.com/NirAharon/BoT-SORT.git\n","%cd BoT-SORT\n","!pip3 install -r requirements.txt\n","!python3 setup.py develop"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wn7Y8b-dxeT8","executionInfo":{"status":"ok","timestamp":1659306921436,"user_tz":-300,"elapsed":15217,"user":{"displayName":"Mujtaba Akbar","userId":"15620186712641886307"}},"outputId":"614a1ca6-0947-406c-afac-721d84868a24"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (0.29.30)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n","  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-y2zrde4f\n","  Running command git clone -q https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-y2zrde4f\n","Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (57.4.0)\n","Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (0.29.30)\n","Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (3.2.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.2)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.21.6)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.4.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (3.0.9)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.1.0->pycocotools==2.0) (4.1.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.1.0->pycocotools==2.0) (1.15.0)\n","Building wheels for collected packages: pycocotools\n","  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pycocotools: filename=pycocotools-2.0-cp37-cp37m-linux_x86_64.whl size=265175 sha256=f8e687815cc385dc5368267143b24d4d459b844e782b44c970034f3292613b34\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-jj4zvuar/wheels/e2/6b/1d/344ac773c7495ea0b85eb228bc66daec7400a143a92d36b7b1\n","Successfully built pycocotools\n","Installing collected packages: pycocotools\n","  Attempting uninstall: pycocotools\n","    Found existing installation: pycocotools 2.0.4\n","    Uninstalling pycocotools-2.0.4:\n","      Successfully uninstalled pycocotools-2.0.4\n","Successfully installed pycocotools-2.0\n"]}],"source":["!pip3 install cython; pip3 install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'"]},{"cell_type":"code","source":["\n","# %mkdir datatest\n","# # %cd datatest\n","# !gdown folders/19loXKpgzEPaOaAhLojyhzvi04wCrPcwD\n","# from google.colab import drive\n","\n","# drive.mount('/content/gdrive')"],"metadata":{"id":"qDV9x4jYy0XD","executionInfo":{"status":"ok","timestamp":1659306921437,"user_tz":-300,"elapsed":7,"user":{"displayName":"Mujtaba Akbar","userId":"15620186712641886307"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OH1-VX_byHO6","executionInfo":{"status":"ok","timestamp":1659306944943,"user_tz":-300,"elapsed":22929,"user":{"displayName":"Mujtaba Akbar","userId":"15620186712641886307"}},"outputId":"51fd7d4f-47b2-4d77-f95e-96222c2fc73b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting cython_bbox\n","  Downloading cython_bbox-0.1.3.tar.gz (41 kB)\n","\u001b[K     |████████████████████████████████| 41 kB 222 kB/s \n","\u001b[?25hBuilding wheels for collected packages: cython-bbox\n","  Building wheel for cython-bbox (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for cython-bbox: filename=cython_bbox-0.1.3-cp37-cp37m-linux_x86_64.whl size=58463 sha256=e23f726f8dcd31ff10928668aac8043695f98c9b59546c07baebc9d94ad372f2\n","  Stored in directory: /root/.cache/pip/wheels/51/82/21/5def8bc98ae4ea436d7f0decb7194d20d7e3e6d0578a4129d7\n","Successfully built cython-bbox\n","Installing collected packages: cython-bbox\n","Successfully installed cython-bbox-0.1.3\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting faiss-cpu\n","  Downloading faiss_cpu-1.7.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n","\u001b[K     |████████████████████████████████| 8.6 MB 5.0 MB/s \n","\u001b[?25hInstalling collected packages: faiss-cpu\n","Successfully installed faiss-cpu-1.7.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting faiss-gpu\n","  Downloading faiss_gpu-1.7.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n","\u001b[K     |████████████████████████████████| 85.5 MB 129 kB/s \n","\u001b[?25hInstalling collected packages: faiss-gpu\n","Successfully installed faiss-gpu-1.7.2\n"]}],"source":["# Cython-bbox\n","!pip3 install cython_bbox\n","\n","# faiss cpu / gpu\n","!pip3 install faiss-cpu\n","!pip3 install faiss-gpu"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12343,"status":"ok","timestamp":1659306957274,"user":{"displayName":"Mujtaba Akbar","userId":"15620186712641886307"},"user_tz":-300},"id":"Oj8QjyKDyN9a","outputId":"c6cc4318-ddf3-484a-dc6f-2622a54f48e3"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/BoT-SORT/pretrained\n","Downloading...\n","From: https://drive.google.com/uc?id=1BF6iX5tF2iKqmY84G7yjQit7pgqw9ws2\n","To: /content/BoT-SORT/pretrained/yolox_x.pth.tar\n","100% 793M/793M [00:02<00:00, 295MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1QZFWpoa80rqo7O-HXmlss8J8CnS7IUsN\n","To: /content/BoT-SORT/pretrained/mot17_sbs_S50.pth\n","100% 318M/318M [00:03<00:00, 93.8MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1dTY1aNUsOOGFqo62RzMnscqGKAgL-SW5\n","To: /content/BoT-SORT/pretrained/yolox_m.pth\n","100% 203M/203M [00:02<00:00, 79.8MB/s]\n"]}],"source":["%mkdir pretrained\n","%cd pretrained\n","!gdown 1BF6iX5tF2iKqmY84G7yjQit7pgqw9ws2\n","!gdown 1QZFWpoa80rqo7O-HXmlss8J8CnS7IUsN\n","# !wget https://objects.githubusercontent.com/github-production-release-asset-2e65be/388351473/77a2128d-8fad-4181-a754-0daf70511100?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220724%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220724T115110Z&X-Amz-Expires=300&X-Amz-Signature=e74e08149842116084b170cc2bd5850546725106ccbd55eb6ed38773bc9139f2&X-Amz-SignedHeaders=host&actor_id=73741881&key_id=0&repo_id=388351473&response-content-disposition=attachment%3B%20filename%3Dyolox_x.pth&response-content-type=application%2Foctet-stream \n","# !gdown 1P4mY0Yyd3PPTybgZkjMYhFri88nTmJX5\n","# !gdown 19UhtPVRn8l6zd_xwBAO6L_RVQu9sKokU\n","!gdown 1dTY1aNUsOOGFqo62RzMnscqGKAgL-SW5\n","# !wget --no-check-certificate https://megvii-my.sharepoint.cn/personal/gezheng_megvii_com/_layouts/15/download.aspx?SourceUrl=%2Fpersonal%2Fgezheng%5Fmegvii%5Fcom%2FDocuments%2Fmodel%5Fcheckpoints%2FYOLOX%2Fyolox%5Fs%2Fyolox%5Fs%2Epth%2Etar\n","# !wget 'https://megvii-my.sharepoint.cn/personal/gezheng_megvii_com/_layouts/15/download.aspx?SourceUrl=%2Fpersonal%2Fgezheng%5Fmegvii%5Fcom%2FDocuments%2Fmodel%5Fcheckpoints%2FYOLOX%2Fyolox%5Fx%2Fyolox%5Fx%2Epth%2Etar'"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10571,"status":"ok","timestamp":1659306967835,"user":{"displayName":"Mujtaba Akbar","userId":"15620186712641886307"},"user_tz":-300},"id":"hKLsKH9w3Mdh","outputId":"75686a34-da73-43f4-8cb6-1207e1d113a7"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/BoT-SORT\n","Downloading...\n","From: https://drive.google.com/uc?id=1Jn2RYxPW6p_j0DS3Lnfcu_HUKANwx7jB\n","To: /content/BoT-SORT/annotate.tar\n","100% 89.4M/89.4M [00:00<00:00, 144MB/s]\n","annotate/\n","annotate/ds0/\n","annotate/ds0/ann/\n","annotate/ds0/ann/A008.mp4.json\n","annotate/ds0/ann/A009.mp4.json\n","annotate/ds0/ann/A010.mp4.json\n","annotate/ds0/ann/A011.mp4.json\n","annotate/ds0/ann/A012.mp4.json\n","annotate/ds0/ann/A013.mp4.json\n","annotate/ds0/ann/A014.mp4.json\n","annotate/ds0/ann/A015.mp4.json\n","annotate/ds0/ann/A016.mp4.json\n","annotate/ds0/ann/A018.mp4.json\n","annotate/ds0/ann/A019.mp4.json\n","annotate/ds0/ann/A020.mp4.json\n","annotate/ds0/ann/A021.mp4.json\n","annotate/ds0/ann/A022.mp4.json\n","annotate/ds0/ann/A023.mp4.json\n","annotate/ds0/ann/A024.mp4.json\n","annotate/ds0/ann/A025.mp4.json\n","annotate/ds0/ann/A026.mp4.json\n","annotate/ds0/ann/A027.mp4.json\n","annotate/ds0/ann/A028.mp4.json\n","annotate/ds0/ann/A029.mp4.json\n","annotate/ds0/ann/A030.mp4.json\n","annotate/ds0/ann/A031.mp4.json\n","annotate/ds0/ann/A032.mp4.json\n","annotate/ds0/ann/A033.mp4.json\n","annotate/ds0/ann/A034.mp4.json\n","annotate/ds0/video/\n","annotate/ds0/video/A008.mp4\n","annotate/ds0/video/A009.mp4\n","annotate/ds0/video/A010.mp4\n","annotate/ds0/video/A011.mp4\n","annotate/ds0/video/A012.mp4\n","annotate/ds0/video/A013.mp4\n","annotate/ds0/video/A014.mp4\n","annotate/ds0/video/A015.mp4\n","annotate/ds0/video/A016.mp4\n","annotate/ds0/video/A018.mp4\n","annotate/ds0/video/A019.mp4\n","annotate/ds0/video/A020.mp4\n","annotate/ds0/video/A021.mp4\n","annotate/ds0/video/A022.mp4\n","annotate/ds0/video/A023.mp4\n","annotate/ds0/video/A024.mp4\n","annotate/ds0/video/A025.mp4\n","annotate/ds0/video/A026.mp4\n","annotate/ds0/video/A027.mp4\n","annotate/ds0/video/A028.mp4\n","annotate/ds0/video/A029.mp4\n","annotate/ds0/video/A030.mp4\n","annotate/ds0/video/A031.mp4\n","annotate/ds0/video/A032.mp4\n","annotate/ds0/video/A033.mp4\n","annotate/ds0/video/A034.mp4\n","annotate/key_id_map.json\n","annotate/meta.json\n"]}],"source":["%cd ..\n","\n","!gdown 1Jn2RYxPW6p_j0DS3Lnfcu_HUKANwx7jB\n","\n","!tar xvf annotate.tar "]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":239189,"status":"ok","timestamp":1659307269690,"user":{"displayName":"Mujtaba Akbar","userId":"15620186712641886307"},"user_tz":-300},"id":"6Mo-u9i6yxqT","outputId":"cacf5526-ff84-4563-c9ca-3f77050c7bc8"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[32m2022-07-31 22:37:13.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m307\u001b[0m - \u001b[1mArgs: Namespace(ablation=False, appearance_thresh=0.25, aspect_ratio_thresh=1.6, camid=0, ckpt='pretrained/yolox_x.pth.tar', cmc_method='orb', conf=None, demo='video', device=device(type='cuda'), exp_file='yolox/exps/default/yolox_x.py', experiment_name='yolox_x', fast_reid_config='fast_reid/configs/MOT17/sbs_S50.yml', fast_reid_weights='pretrained/mot17_sbs_S50.pth', fp16=True, fps=30, fuse=True, fuse_score=True, match_thresh=0.8, min_box_area=10, mot20=False, name=None, new_track_thresh=0.7, nms=None, path='annotate/ds0/video/A030.mp4', proximity_thresh=0.5, save_result=True, track_buffer=30, track_high_thresh=0.6, track_low_thresh=0.1, trt=False, tsize=None, with_reid=True)\u001b[0m\n","/usr/local/lib/python3.7/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","\u001b[32m2022-07-31 22:37:23.796\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m317\u001b[0m - \u001b[1mModel Summary: Params: 99.07M, Gflops: 282.46\u001b[0m\n","\u001b[32m2022-07-31 22:37:23.799\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m325\u001b[0m - \u001b[1mloading checkpoint\u001b[0m\n","\u001b[32m2022-07-31 22:37:24.485\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m329\u001b[0m - \u001b[1mloaded checkpoint done.\u001b[0m\n","\u001b[32m2022-07-31 22:37:24.485\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m332\u001b[0m - \u001b[1m\tFusing model...\u001b[0m\n","/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:1083: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  aten/src/ATen/core/TensorBody.h:477.)\n","  return self._grad\n","\u001b[32m2022-07-31 22:37:25.467\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m230\u001b[0m - \u001b[1mvideo save_path is ./YOLOX_outputs/yolox_x/track_vis/2022_07_31_22_37_25/A030.mp4\u001b[0m\n","Skip loading parameter 'heads.weight' to the model due to incompatible shapes: (487, 2048) in the checkpoint but (0, 2048) in the model! You might want to double check if this is expected.\n","\u001b[32m2022-07-31 22:37:26.285\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1mProcessing frame 0 (100000.00 fps)\u001b[0m\n","\u001b[32m2022-07-31 22:37:31.318\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1mProcessing frame 20 (5.10 fps)\u001b[0m\n","\u001b[32m2022-07-31 22:37:35.603\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1mProcessing frame 40 (5.61 fps)\u001b[0m\n","\u001b[32m2022-07-31 22:37:39.653\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1mProcessing frame 60 (5.93 fps)\u001b[0m\n","\u001b[32m2022-07-31 22:37:43.898\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1mProcessing frame 80 (6.02 fps)\u001b[0m\n","\u001b[32m2022-07-31 22:37:48.679\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1mProcessing frame 100 (5.88 fps)\u001b[0m\n","\u001b[32m2022-07-31 22:37:53.544\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1mProcessing frame 120 (5.76 fps)\u001b[0m\n","\u001b[32m2022-07-31 22:37:59.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1mProcessing frame 140 (5.52 fps)\u001b[0m\n","\u001b[32m2022-07-31 22:38:04.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1mProcessing frame 160 (5.41 fps)\u001b[0m\n","\u001b[32m2022-07-31 22:38:06.864\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1msave results to ./YOLOX_outputs/yolox_x/track_vis/2022_07_31_22_37_25.txt\u001b[0m\n","\u001b[32m2022-07-31 22:38:09.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m307\u001b[0m - \u001b[1mArgs: Namespace(ablation=False, appearance_thresh=0.25, aspect_ratio_thresh=1.6, camid=0, ckpt='pretrained/yolox_x.pth.tar', cmc_method='orb', conf=None, demo='video', device=device(type='cuda'), exp_file='yolox/exps/default/yolox_x.py', experiment_name='yolox_x', fast_reid_config='fast_reid/configs/MOT17/sbs_S50.yml', fast_reid_weights='pretrained/mot17_sbs_S50.pth', fp16=True, fps=30, fuse=True, fuse_score=True, match_thresh=0.8, min_box_area=10, mot20=False, name=None, new_track_thresh=0.7, nms=None, path='annotate/ds0/video/A031.mp4', proximity_thresh=0.5, save_result=True, track_buffer=30, track_high_thresh=0.6, track_low_thresh=0.1, trt=False, tsize=None, with_reid=True)\u001b[0m\n","/usr/local/lib/python3.7/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","\u001b[32m2022-07-31 22:38:14.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m317\u001b[0m - \u001b[1mModel Summary: Params: 99.07M, Gflops: 282.46\u001b[0m\n","\u001b[32m2022-07-31 22:38:14.084\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m325\u001b[0m - \u001b[1mloading checkpoint\u001b[0m\n","\u001b[32m2022-07-31 22:38:14.773\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m329\u001b[0m - \u001b[1mloaded checkpoint done.\u001b[0m\n","\u001b[32m2022-07-31 22:38:14.774\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m332\u001b[0m - \u001b[1m\tFusing model...\u001b[0m\n","/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:1083: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  aten/src/ATen/core/TensorBody.h:477.)\n","  return self._grad\n","\u001b[32m2022-07-31 22:38:15.652\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m230\u001b[0m - \u001b[1mvideo save_path is ./YOLOX_outputs/yolox_x/track_vis/2022_07_31_22_38_15/A031.mp4\u001b[0m\n","Skip loading parameter 'heads.weight' to the model due to incompatible shapes: (487, 2048) in the checkpoint but (0, 2048) in the model! You might want to double check if this is expected.\n","\u001b[32m2022-07-31 22:38:16.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1mProcessing frame 0 (100000.00 fps)\u001b[0m\n","\u001b[32m2022-07-31 22:38:22.214\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1mProcessing frame 20 (4.21 fps)\u001b[0m\n","\u001b[32m2022-07-31 22:38:28.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1mProcessing frame 40 (4.14 fps)\u001b[0m\n","\u001b[32m2022-07-31 22:38:33.795\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1mProcessing frame 60 (4.18 fps)\u001b[0m\n","\u001b[32m2022-07-31 22:38:38.857\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1mProcessing frame 80 (4.35 fps)\u001b[0m\n","\u001b[32m2022-07-31 22:38:44.226\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1mProcessing frame 100 (4.40 fps)\u001b[0m\n","\u001b[32m2022-07-31 22:38:44.476\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1msave results to ./YOLOX_outputs/yolox_x/track_vis/2022_07_31_22_38_15.txt\u001b[0m\n","\u001b[32m2022-07-31 22:38:47.149\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m307\u001b[0m - \u001b[1mArgs: Namespace(ablation=False, appearance_thresh=0.25, aspect_ratio_thresh=1.6, camid=0, ckpt='pretrained/yolox_x.pth.tar', cmc_method='orb', conf=None, demo='video', device=device(type='cuda'), exp_file='yolox/exps/default/yolox_x.py', experiment_name='yolox_x', fast_reid_config='fast_reid/configs/MOT17/sbs_S50.yml', fast_reid_weights='pretrained/mot17_sbs_S50.pth', fp16=True, fps=30, fuse=True, fuse_score=True, match_thresh=0.8, min_box_area=10, mot20=False, name=None, new_track_thresh=0.7, nms=None, path='annotate/ds0/video/A032.mp4', proximity_thresh=0.5, save_result=True, track_buffer=30, track_high_thresh=0.6, track_low_thresh=0.1, trt=False, tsize=None, with_reid=True)\u001b[0m\n","/usr/local/lib/python3.7/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","\u001b[32m2022-07-31 22:38:51.422\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m317\u001b[0m - \u001b[1mModel Summary: Params: 99.07M, Gflops: 282.46\u001b[0m\n","\u001b[32m2022-07-31 22:38:51.425\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m325\u001b[0m - \u001b[1mloading checkpoint\u001b[0m\n","\u001b[32m2022-07-31 22:38:52.098\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m329\u001b[0m - \u001b[1mloaded checkpoint done.\u001b[0m\n","\u001b[32m2022-07-31 22:38:52.098\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m332\u001b[0m - \u001b[1m\tFusing model...\u001b[0m\n","/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:1083: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  aten/src/ATen/core/TensorBody.h:477.)\n","  return self._grad\n","\u001b[32m2022-07-31 22:38:52.970\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m230\u001b[0m - \u001b[1mvideo save_path is ./YOLOX_outputs/yolox_x/track_vis/2022_07_31_22_38_52/A032.mp4\u001b[0m\n","Skip loading parameter 'heads.weight' to the model due to incompatible shapes: (487, 2048) in the checkpoint but (0, 2048) in the model! You might want to double check if this is expected.\n","\u001b[32m2022-07-31 22:38:53.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1mProcessing frame 0 (100000.00 fps)\u001b[0m\n","\u001b[32m2022-07-31 22:38:59.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1mProcessing frame 20 (4.17 fps)\u001b[0m\n","\u001b[32m2022-07-31 22:39:05.482\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1mProcessing frame 40 (4.21 fps)\u001b[0m\n","\u001b[32m2022-07-31 22:39:11.094\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1mProcessing frame 60 (4.26 fps)\u001b[0m\n","\u001b[32m2022-07-31 22:39:15.649\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1mProcessing frame 80 (4.55 fps)\u001b[0m\n","\u001b[32m2022-07-31 22:39:20.891\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1mProcessing frame 100 (4.59 fps)\u001b[0m\n","\u001b[32m2022-07-31 22:39:25.503\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1msave results to ./YOLOX_outputs/yolox_x/track_vis/2022_07_31_22_38_52.txt\u001b[0m\n","\u001b[32m2022-07-31 22:39:28.192\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m307\u001b[0m - \u001b[1mArgs: Namespace(ablation=False, appearance_thresh=0.25, aspect_ratio_thresh=1.6, camid=0, ckpt='pretrained/yolox_x.pth.tar', cmc_method='orb', conf=None, demo='video', device=device(type='cuda'), exp_file='yolox/exps/default/yolox_x.py', experiment_name='yolox_x', fast_reid_config='fast_reid/configs/MOT17/sbs_S50.yml', fast_reid_weights='pretrained/mot17_sbs_S50.pth', fp16=True, fps=30, fuse=True, fuse_score=True, match_thresh=0.8, min_box_area=10, mot20=False, name=None, new_track_thresh=0.7, nms=None, path='annotate/ds0/video/A033.mp4', proximity_thresh=0.5, save_result=True, track_buffer=30, track_high_thresh=0.6, track_low_thresh=0.1, trt=False, tsize=None, with_reid=True)\u001b[0m\n","/usr/local/lib/python3.7/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","\u001b[32m2022-07-31 22:39:32.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m317\u001b[0m - \u001b[1mModel Summary: Params: 99.07M, Gflops: 282.46\u001b[0m\n","\u001b[32m2022-07-31 22:39:32.476\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m325\u001b[0m - \u001b[1mloading checkpoint\u001b[0m\n","\u001b[32m2022-07-31 22:39:33.157\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m329\u001b[0m - \u001b[1mloaded checkpoint done.\u001b[0m\n","\u001b[32m2022-07-31 22:39:33.157\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m332\u001b[0m - \u001b[1m\tFusing model...\u001b[0m\n","/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:1083: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  aten/src/ATen/core/TensorBody.h:477.)\n","  return self._grad\n","\u001b[32m2022-07-31 22:39:34.046\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m230\u001b[0m - \u001b[1mvideo save_path is ./YOLOX_outputs/yolox_x/track_vis/2022_07_31_22_39_34/A033.mp4\u001b[0m\n","Skip loading parameter 'heads.weight' to the model due to incompatible shapes: (487, 2048) in the checkpoint but (0, 2048) in the model! You might want to double check if this is expected.\n","\u001b[32m2022-07-31 22:39:34.810\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1mProcessing frame 0 (100000.00 fps)\u001b[0m\n","\u001b[32m2022-07-31 22:39:42.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1mProcessing frame 20 (3.07 fps)\u001b[0m\n","\u001b[32m2022-07-31 22:39:51.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1mProcessing frame 40 (2.86 fps)\u001b[0m\n","\u001b[32m2022-07-31 22:39:55.798\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1mProcessing frame 60 (3.43 fps)\u001b[0m\n","\u001b[32m2022-07-31 22:40:01.469\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1mProcessing frame 80 (3.62 fps)\u001b[0m\n","Traceback (most recent call last):\n","  File \"tools/demo.py\", line 368, in <module>\n","    main(exp, args)\n","  File \"tools/demo.py\", line 356, in main\n","    imageflow_demo(predictor, vis_folder, current_time, args)\n","  File \"tools/demo.py\", line 253, in imageflow_demo\n","    online_targets = tracker.update(detections, img_info[\"raw_img\"])\n","  File \"/content/BoT-SORT/tracker/bot_sort.py\", line 298, in update\n","    warp = self.gmc.apply(img, dets)\n","  File \"/content/BoT-SORT/tracker/gmc.py\", line 62, in apply\n","    return self.applyFeaures(raw_frame, detections)\n","  File \"/content/BoT-SORT/tracker/gmc.py\", line 146, in applyFeaures\n","    knnMatches = self.matcher.knnMatch(self.prevDescriptors, descriptors, 2)\n","KeyboardInterrupt\n","\u001b[32m2022-07-31 22:40:07.091\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m307\u001b[0m - \u001b[1mArgs: Namespace(ablation=False, appearance_thresh=0.25, aspect_ratio_thresh=1.6, camid=0, ckpt='pretrained/yolox_x.pth.tar', cmc_method='orb', conf=None, demo='video', device=device(type='cuda'), exp_file='yolox/exps/default/yolox_x.py', experiment_name='yolox_x', fast_reid_config='fast_reid/configs/MOT17/sbs_S50.yml', fast_reid_weights='pretrained/mot17_sbs_S50.pth', fp16=True, fps=30, fuse=True, fuse_score=True, match_thresh=0.8, min_box_area=10, mot20=False, name=None, new_track_thresh=0.7, nms=None, path='annotate/ds0/video/A034.mp4', proximity_thresh=0.5, save_result=True, track_buffer=30, track_high_thresh=0.6, track_low_thresh=0.1, trt=False, tsize=None, with_reid=True)\u001b[0m\n","/usr/local/lib/python3.7/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","\u001b[32m2022-07-31 22:40:11.349\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m317\u001b[0m - \u001b[1mModel Summary: Params: 99.07M, Gflops: 282.46\u001b[0m\n","\u001b[32m2022-07-31 22:40:11.352\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m325\u001b[0m - \u001b[1mloading checkpoint\u001b[0m\n","\u001b[32m2022-07-31 22:40:12.035\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m329\u001b[0m - \u001b[1mloaded checkpoint done.\u001b[0m\n","\u001b[32m2022-07-31 22:40:12.035\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m332\u001b[0m - \u001b[1m\tFusing model...\u001b[0m\n","/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:1083: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  aten/src/ATen/core/TensorBody.h:477.)\n","  return self._grad\n","\u001b[32m2022-07-31 22:40:12.917\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m230\u001b[0m - \u001b[1mvideo save_path is ./YOLOX_outputs/yolox_x/track_vis/2022_07_31_22_40_12/A034.mp4\u001b[0m\n","Skip loading parameter 'heads.weight' to the model due to incompatible shapes: (487, 2048) in the checkpoint but (0, 2048) in the model! You might want to double check if this is expected.\n","\u001b[32m2022-07-31 22:40:13.678\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1mProcessing frame 0 (100000.00 fps)\u001b[0m\n","\u001b[32m2022-07-31 22:40:22.904\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1mProcessing frame 20 (2.45 fps)\u001b[0m\n","\u001b[32m2022-07-31 22:40:32.738\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1mProcessing frame 40 (2.36 fps)\u001b[0m\n","\u001b[32m2022-07-31 22:40:43.233\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1mProcessing frame 60 (2.27 fps)\u001b[0m\n","\u001b[32m2022-07-31 22:40:55.184\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1mProcessing frame 80 (2.14 fps)\u001b[0m\n","\u001b[32m2022-07-31 22:41:07.296\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1mProcessing frame 100 (2.07 fps)\u001b[0m\n","Traceback (most recent call last):\n","  File \"tools/demo.py\", line 368, in <module>\n","    main(exp, args)\n","  File \"tools/demo.py\", line 356, in main\n","    imageflow_demo(predictor, vis_folder, current_time, args)\n","  File \"tools/demo.py\", line 244, in imageflow_demo\n","    outputs, img_info = predictor.inference(frame, timer)\n","  File \"tools/demo.py\", line 140, in inference\n","    outputs = self.model(img)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/content/BoT-SORT/yolox/models/yolox.py\", line 30, in forward\n","    fpn_outs = self.backbone(x)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/content/BoT-SORT/yolox/models/yolo_pafpn.py\", line 98, in forward\n","    f_out0 = self.upsample(fpn_out0)  # 512/16\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/upsampling.py\", line 154, in forward\n","    recompute_scale_factor=self.recompute_scale_factor)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\", line 3910, in interpolate\n","    return torch._C._nn.upsample_nearest2d(input, output_size, scale_factors)\n","KeyboardInterrupt\n"]}],"source":["# !python3 tools/demo.py video --path fishraw1.mp4 -f yolox/exps/default/yolox_x.py -c pretrained/yolox_x.pth.tar --with-reid --fuse-score --fp16 --fuse --save_result\n","# !python3 tools/demo.py video --path fishraw2.mp4 -f yolox/exps/default/yolox_x.py -c pretrained/yolox_x.pth.tar --with-reid --fuse-score --fp16 --fuse --save_result\n","# !python3 tools/demo.py video --path fishraw3.mp4 -f yolox/exps/default/yolox_x.py -c pretrained/yolox_x.pth.tar --with-reid --fuse-score --fp16 --fuse --save_result\n","# !python3 tools/demo.py video --path fishraw4.mp4 -f yolox/exps/default/yolox_x.py -c pretrained/yolox_x.pth.tar --with-reid --fuse-score --fp16 --fuse --save_result\n","# !python3 tools/demo.py video --path fishraw5.mp4 -f yolox/exps/default/yolox_x.py -c pretrained/yolox_x.pth.tar --with-reid --fuse-score --fp16 --fuse --save_result\n","\n","\n","!python3 tools/demo.py video --path annotate/ds0/video/A030.mp4 -f yolox/exps/default/yolox_x.py -c pretrained/yolox_x.pth.tar --with-reid --fuse-score --fp16 --fuse --save_result\n","!python3 tools/demo.py video --path annotate/ds0/video/A031.mp4 -f yolox/exps/default/yolox_x.py -c pretrained/yolox_x.pth.tar --with-reid --fuse-score --fp16 --fuse --save_result\n","!python3 tools/demo.py video --path annotate/ds0/video/A032.mp4 -f yolox/exps/default/yolox_x.py -c pretrained/yolox_x.pth.tar --with-reid --fuse-score --fp16 --fuse --save_result\n","!python3 tools/demo.py video --path annotate/ds0/video/A033.mp4 -f yolox/exps/default/yolox_x.py -c pretrained/yolox_x.pth.tar --with-reid --fuse-score --fp16 --fuse --save_result\n","!python3 tools/demo.py video --path annotate/ds0/video/A034.mp4 -f yolox/exps/default/yolox_x.py -c pretrained/yolox_x.pth.tar --with-reid --fuse-score --fp16 --fuse --save_result\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Uhm2LFMLC0wZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659303233317,"user_tz":-300,"elapsed":4424,"user":{"displayName":"Mujtaba Akbar","userId":"15620186712641886307"}},"outputId":"1b78e506-c237-44d2-bdd5-8e16b93bd4f6"},"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: YOLOX_outputs/ (stored 0%)\n","  adding: YOLOX_outputs/yolox_x/ (stored 0%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/ (stored 0%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_23_04.txt (deflated 13%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_21_59.txt (stored 0%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_21_38/ (stored 0%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_21_38/A020.mp4 (deflated 2%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_30_57.txt (deflated 61%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_20_55/ (stored 0%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_20_55/A018.mp4 (deflated 5%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_13_50/ (stored 0%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_28_50/ (stored 0%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_28_50/A030.mp4 (deflated 1%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_21_59/ (stored 0%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_21_59/A021.mp4 (deflated 2%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_22_43.txt (deflated 57%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_18_26.txt (deflated 61%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_23_04/ (stored 0%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_23_04/A024.mp4 (deflated 1%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_22_43/ (stored 0%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_22_43/A023.mp4 (deflated 2%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_13_50.txt (stored 0%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_22_21/ (stored 0%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_22_21/A022.mp4 (deflated 4%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_28_50.txt (deflated 63%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_25_48/ (stored 0%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_25_48/A028.mp4 (deflated 0%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_30_17.txt (deflated 63%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_20_25/ (stored 0%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_20_25/A016.mp4 (deflated 5%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_19_34/ (stored 0%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_19_34/A013.mp4 (deflated 7%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_27_48/ (stored 0%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_27_48/A029.mp4 (deflated 1%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_23_56/ (stored 0%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_23_56/A027.mp4 (deflated 0%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_20_55.txt (deflated 58%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_23_38/ (stored 0%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_23_38/A026.mp4 (deflated 8%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_19_50/ (stored 0%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_19_50/A014.mp4 (deflated 6%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_23_38.txt (stored 0%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_14_38.txt (deflated 64%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_31_38/ (stored 0%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_31_38/A034.mp4 (deflated 1%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_25_48.txt (deflated 16%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_19_10/ (stored 0%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_19_10/A012.mp4 (deflated 6%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_22_21.txt (deflated 61%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_20_04.txt (stored 0%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_17_45/ (stored 0%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_17_45/A009.mp4 (deflated 1%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_20_45/ (stored 0%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_18_48.txt (stored 0%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_20_04/ (stored 0%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_20_04/A015.mp4 (deflated 8%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_14_38/ (stored 0%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_14_38/A008.mp4 (deflated 0%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_23_25/ (stored 0%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_23_25/A025.mp4 (deflated 1%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_27_48.txt (deflated 62%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_21_38.txt (deflated 57%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_31_38.txt (deflated 62%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_21_17.txt (deflated 58%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_23_56.txt (stored 0%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_18_26/ (stored 0%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_18_26/A010.mp4 (deflated 7%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_18_48/ (stored 0%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_18_48/A011.mp4 (deflated 4%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_19_10.txt (stored 0%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_20_25.txt (deflated 57%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_17_45.txt (deflated 61%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_21_17/ (stored 0%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_21_17/A019.mp4 (deflated 2%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_30_57/ (stored 0%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_30_57/A033.mp4 (deflated 1%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_20_45.txt (stored 0%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_29_39/ (stored 0%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_29_39/A031.mp4 (deflated 1%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_29_39.txt (deflated 62%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_30_17/ (stored 0%)\n","  adding: YOLOX_outputs/yolox_x/track_vis/2022_07_31_21_30_17/A032.mp4 (deflated 2%)\n"]}],"source":["!zip -r file.zip YOLOX_outputs\n"]},{"cell_type":"code","source":[""],"metadata":{"id":"nlSB2LfdLfEz"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"BoT-SORT.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}